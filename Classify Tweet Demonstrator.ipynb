{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["_NFIH3fy_CFA"],"authorship_tag":"ABX9TyO6zOeXRZ1mZ8iaw7ieBk4r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Offensive Language Identification in Social Media: Building a Model for Detecting and Categorising Offensive Tweets"],"metadata":{"id":"xGVe6ndT3ceG"}},{"cell_type":"markdown","source":["This notebook combines the 3 models trained to categorise offensive tweets into 3 differnt levels: **A**, **B**, and **C**. **Level\n","A** is for identifying whether a post is **offensive** or\n","**not**. **Level B**, is for identifying whether a tweet contains an insult or threat to an individual, labelled as **\"TIN\"**, while **Level C** is for offence target identification. An instance is labelled as **\"IND\"** if the target of the offensive post is an individual, \"GRP\" if the target is a group, and **\"OTH\"** if the target does not belong to any of the previous two categories."],"metadata":{"id":"f2dxL_r33hoK"}},{"cell_type":"markdown","source":["##Import Libraries"],"metadata":{"id":"ya5qru_P--PK"}},{"cell_type":"code","source":["!python --version\n","!pip install transformers --quiet\n","!pip install pytorch-lightning --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nVN0UHKq9klW","executionInfo":{"status":"ok","timestamp":1682525575082,"user_tz":-60,"elapsed":7568,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}},"outputId":"c4ff2b87-de16-49bd-852b-06f6592d2ba8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.9.16\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import lr_scheduler\n","\n","from transformers import BertTokenizerFast as BertTokenizer, BertModel, AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n","from transformers import logging\n","logging.set_verbosity_error()\n","\n","import pytorch_lightning as pl\n","from torchmetrics.functional import auroc, accuracy\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","from pytorch_lightning.loggers import TensorBoardLogger"],"metadata":{"id":"O5dK-rgh9bjK","executionInfo":{"status":"ok","timestamp":1682525576956,"user_tz":-60,"elapsed":3,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["bert_model = bert = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"],"metadata":{"id":"bHeK57EDLJ6O","executionInfo":{"status":"ok","timestamp":1682525580552,"user_tz":-60,"elapsed":1834,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Define Model Architectures"],"metadata":{"id":"_NFIH3fy_CFA"}},{"cell_type":"code","source":["class OffensiveTweetTagger_taskA(pl.LightningModule):\n","  def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n","    super().__init__()\n","    self.bert = bert_model\n","    # classifier: serve as a way to get the output of the BERT model and convert those into the num of classes which we want to predict\n","    self.classifier1 = nn.Linear(self.bert.config.hidden_size, n_classes)\n","    self.dropOutLayer = nn.Dropout(p=0.1)\n","    self.relu = nn.ReLU()\n","    self.n_training_steps = n_training_steps\n","    self.n_warmup_steps = n_warmup_steps\n","    self.classifier2 = nn.Linear(2, 1)\n","    # This criterion computes the cross entropy loss between input logits and target\n","    self.criterion = nn.BCELoss()\n","    \n","  def forward(self, input_ids, attention_mask, labels=None):\n","    output = self.bert(input_ids, attention_mask=attention_mask)\n","    # run linear layer ontop of the output\n","    output = self.classifier1(output.pooler_output)\n","    output = self.relu(output)\n","    output = self.dropOutLayer(output)\n","    output = self.classifier2(output)\n","    # apply sigmoid function\n","    output = torch.sigmoid(output)\n","    loss = 0\n","    if labels is not None:\n","      loss = self.criterion(output, labels)\n","    return loss, output\n","\n","  def training_step(self, batch, batch_idx):\n","    input_ids = batch['input_ids']\n","    attention_mask = batch['attention_mask']\n","    labels = batch['label']\n","    loss, outputs = self.forward(input_ids, attention_mask, labels)\n","    # output training loss\n","    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n","    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n","\n","  def validation_step(self, batch, batch_idx):\n","    input_ids = batch['input_ids']\n","    attention_mask = batch['attention_mask']\n","    labels = batch['label']\n","    loss, outputs = self.forward(input_ids, attention_mask, labels)\n","    # output training loss\n","    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n","    return loss\n","  \n","  def test_step(self, batch, batch_idx):\n","    input_ids = batch['input_ids']\n","    attention_mask = batch['attention_mask']\n","    labels = batch['label']\n","    loss, outputs = self.forward(input_ids, attention_mask, labels)\n","    # output training loss\n","    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n","    return loss\n","\n","  # configer optimisers and learning rate scheduler\n","  def configure_optimizers(self):\n","    optimizer = AdamW(self.parameters(), lr=5e-5)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=self.n_warmup_steps,\n","        num_training_steps=self.n_training_steps\n","    )\n","\n","    # return a list of optimisers and schedulers\n","    return dict(\n","        optimizer=optimizer,\n","        lr_scheduler=dict(\n","            scheduler=scheduler,\n","            interval='step'\n","        )\n","    )"],"metadata":{"id":"-W3wRtz-9T-a","executionInfo":{"status":"ok","timestamp":1682525582371,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class OffensiveTweetTagger_taskC(pl.LightningModule):\n","  def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n","    super().__init__()\n","    self.bert = bert_model\n","    # classifier: serve as a way to get the output of the BERT model and convert those into the num of classes which we want to predict\n","    self.classifier1 = nn.Linear(self.bert.config.hidden_size, 16)\n","    self.dropOutLayer = nn.Dropout(p=0.1)\n","    self.relu = nn.ReLU()\n","    self.n_training_steps = n_training_steps\n","    self.n_warmup_steps = n_warmup_steps\n","    self.classifier2 = nn.Linear(16, n_classes)\n","    # This criterion computes the cross entropy loss between input logits and target\n","    self.criterion = nn.BCELoss()\n","\n","  def forward(self, input_ids, attention_mask, labels=None):\n","    output = self.bert(input_ids, attention_mask=attention_mask)\n","    # run linear layer ontop of the output\n","    output = self.classifier1(output.pooler_output)\n","    output = self.relu(output)\n","    output = self.dropOutLayer(output)\n","    output = self.classifier2(output)\n","    # apply sigmoid function\n","    output = torch.sigmoid(output)\n","    loss = 0\n","    if labels is not None:\n","      loss = self.criterion(output, labels)\n","    return loss, output\n","\n","  def training_step(self, batch, batch_idx):\n","    input_ids = batch['input_ids']\n","    attention_mask = batch['attention_mask']\n","    labels = batch['label']\n","    loss, outputs = self.forward(input_ids, attention_mask, labels)\n","    # output training loss\n","    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n","    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n","\n","  def validation_step(self, batch, batch_idx):\n","    input_ids = batch['input_ids']\n","    attention_mask = batch['attention_mask']\n","    labels = batch['label']\n","    loss, outputs = self.forward(input_ids, attention_mask, labels)\n","    # output training loss\n","    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n","    return loss\n","  \n","  def test_step(self, batch, batch_idx):\n","    input_ids = batch['input_ids']\n","    attention_mask = batch['attention_mask']\n","    labels = batch['label']\n","    loss, outputs = self.forward(input_ids, attention_mask, labels)\n","    # output training loss\n","    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n","    return loss\n","\n","  # configer optimisers and learning rate scheduler\n","  def configure_optimizers(self):\n","    optimizer = AdamW(self.parameters(), lr=5e-5)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps=self.n_warmup_steps,\n","        num_training_steps=self.n_training_steps\n","    )\n","\n","    # return a list of optimisers and schedulers\n","    return dict(\n","        optimizer=optimizer,\n","        lr_scheduler=dict(\n","            scheduler=scheduler,\n","            interval='step'\n","        )\n","    )"],"metadata":{"id":"AbAPDUOsEelU","executionInfo":{"status":"ok","timestamp":1682525582371,"user_tz":-60,"elapsed":1,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["##Pre-Process Tweet"],"metadata":{"id":"iJwnrAZr_wqp"}},{"cell_type":"code","source":["def PreProcessing(tweet: str, tokenizer: AutoTokenizer, max_token_len: int=128):\n","  encoding = tokenizer.encode_plus(\n","        tweet,\n","        add_special_tokens=True,\n","        max_length=max_token_len,\n","        return_token_type_ids=False,\n","        padding=\"max_length\",\n","        truncation=True,\n","        return_attention_mask=True,\n","        return_tensors=\"pt\"\n","    )\n","  return dict(\n","        tweet=tweet,\n","        input_ids=encoding[\"input_ids\"],\n","        attention_mask=encoding[\"attention_mask\"]\n","        )   "],"metadata":{"id":"uCvwDMpR_wUY","executionInfo":{"status":"ok","timestamp":1682525583990,"user_tz":-60,"elapsed":1,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["##Load Trained Models"],"metadata":{"id":"A2jo6LOn7qw0"}},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bPg9hkb0Ke5","executionInfo":{"status":"ok","timestamp":1682527301688,"user_tz":-60,"elapsed":19914,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}},"outputId":"aaf6b1e2-97bd-4b0f-99d4-67a8d7b08ebf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=104mHPrMOJ6ayMgzV0oiE46gOHtG-greh\n","To: /content/subtask_a_best_model.ckpt\n","100% 438M/438M [00:09<00:00, 44.2MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1-2dmyv3Zb9W-ZDSPjlTUE9Arg5xF2foh\n","To: /content/subtask_b_best_model.ckpt\n","100% 438M/438M [00:01<00:00, 219MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1--kGa5q49ggK4hNOeAHFHQP3NkYXP6kN\n","To: /content/subtask_c_best_model.ckpt\n","100% 438M/438M [00:01<00:00, 260MB/s]\n"]}],"source":["#Trained model for subtask_A\n","!gdown 104mHPrMOJ6ayMgzV0oiE46gOHtG-greh\n","#Trained model for subtask_B\n","!gdown 1-2dmyv3Zb9W-ZDSPjlTUE9Arg5xF2foh\n","#Trained model for subtask_C\n","!gdown 1--kGa5q49ggK4hNOeAHFHQP3NkYXP6kN\n"]},{"cell_type":"code","source":["def ClassifyTweet(tweet):\n","  trained_model_A = OffensiveTweetTagger_taskA.load_from_checkpoint(\n","    \"subtask_a_best_model.ckpt\",\n","    n_classes=2\n","  )\n","  trained_model_A.eval()\n","  trained_model_A.freeze()\n","\n","  trained_model_B = OffensiveTweetTagger_taskA.load_from_checkpoint(\n","    \"subtask_b_best_model.ckpt\",\n","    n_classes=2\n","  )\n","  trained_model_B.eval()\n","  trained_model_B.freeze()\n","\n","  trained_model_C = OffensiveTweetTagger_taskC.load_from_checkpoint(\n","    \"subtask_c_best_model.ckpt\",\n","    n_classes=3\n","  )\n","  trained_model_C.eval()\n","  trained_model_C.freeze()\n","\n","  model_A_input = PreProcessing(tweet, tokenizer, 80)\n","  model_B_input = PreProcessing(tweet, tokenizer, 50)\n","  model_C_input = PreProcessing(tweet, tokenizer, 60)\n","\n","  trained_model_A.to('cpu')\n","  trained_model_B.to('cpu')\n","  trained_model_C.to('cpu')\n","\n","  print(\"Tweet: \", tweet)\n","\n","  # Calculate Predictions\n","  _, test_prediction_a = trained_model_A(model_A_input['input_ids'], model_A_input['attention_mask'])\n","  test_prediction_a = test_prediction_a.flatten().numpy()\n","  _, test_prediction_b = trained_model_B(model_B_input['input_ids'], model_B_input['attention_mask'])\n","  test_prediction_b = test_prediction_b.flatten().numpy()\n","  _, test_prediction_c = trained_model_C(model_C_input['input_ids'], model_C_input['attention_mask'])\n","  test_prediction_c = test_prediction_c.flatten().numpy()\n","  test_prediction_c[test_prediction_c.argmax()] = 1\n","\n","  print(\"Subtask_A: \", end=\"\")\n","  if(test_prediction_a[0] > 0.5):\n","    print(\"This tweet is OFFENSIVE\")\n","  else:\n","    print(\"This tweet is NOT OFFENSIVE\")\n","    return\n","  print(\"Subtask_B: \", end=\"\")\n","  if(test_prediction_b[0] > 0.5):\n","    print(\"This tweet is a Targeted Insult\")\n","  else:\n","    print(\"This tweet is Untargeted\")\n","    return\n","  print(\"Subtask_C: \", end=\"\")\n","  if (test_prediction_c[0]==1):\n","    print(\"This tweet is targeted at an INDividual\")\n","  elif (test_prediction_c[1]==1):\n","    print(\"This tweet is targeted at OTH than an individual or group\")\n","  else:\n","    print(\"This tweet is targeted at a Group (GRP)\")"],"metadata":{"id":"URnYSPfv8qCS","executionInfo":{"status":"ok","timestamp":1682527498189,"user_tz":-60,"elapsed":3,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["tweet = input(\"Enter a tweet to classify: \")\n","ClassifyTweet(tweet)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmJA8pAp-SPr","executionInfo":{"status":"ok","timestamp":1682527667728,"user_tz":-60,"elapsed":7650,"user":{"displayName":"Mohammad Zaeem","userId":"14042025931783946748"}},"outputId":"ec0f38e6-8b1a-4d8d-9d46-50652a75b95b"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter a tweet to classify: #FortniteBattleRoyale #XboxShare @USER   Please ban this cheating scum.  he is literally invisible URL\n","Tweet:  #FortniteBattleRoyale #XboxShare @USER   Please ban this cheating scum.  he is literally invisible URL\n","Subtask_A: This tweet is OFFENSIVE\n","Subtask_B: This tweet is a Targeted Insult\n","Subtask_C: This tweet is targeted at a Group (GRP)\n"]}]}]}